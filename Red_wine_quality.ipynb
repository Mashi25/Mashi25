{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mashi25/Red-Wine-Quality-Analysis/blob/main/Red_wine_quality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHvdwypll4BI"
      },
      "source": [
        "\n",
        "\n",
        "Red Wine Quality\n",
        "\n",
        "G Nafisa Mashitha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrUhE26Xbihd"
      },
      "source": [
        "#REGRESSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "494JHK4OFVhA"
      },
      "source": [
        "##Preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hj1uBiK2A5c"
      },
      "source": [
        "Importing relevant libraries required for the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4mIyZRkmGPn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXNUUb602G4N"
      },
      "source": [
        "Reading the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLdRSX8uApda"
      },
      "source": [
        "dataset= pd.read_csv('/content/winequality-red.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIu-w-N5ArKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f1ae7e-2185-4881-aa15-6fd4a2c998a5"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0               7.4             0.700         0.00  ...       0.56      9.4        5\n",
              "1               7.8             0.880         0.00  ...       0.68      9.8        5\n",
              "2               7.8             0.760         0.04  ...       0.65      9.8        5\n",
              "3              11.2             0.280         0.56  ...       0.58      9.8        6\n",
              "4               7.4             0.700         0.00  ...       0.56      9.4        5\n",
              "...             ...               ...          ...  ...        ...      ...      ...\n",
              "1594            6.2             0.600         0.08  ...       0.58     10.5        5\n",
              "1595            5.9             0.550         0.10  ...       0.76     11.2        6\n",
              "1596            6.3             0.510         0.13  ...       0.75     11.0        6\n",
              "1597            5.9             0.645         0.12  ...       0.71     10.2        5\n",
              "1598            6.0             0.310         0.47  ...       0.66     11.0        6\n",
              "\n",
              "[1599 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWAZrEjNDHo3"
      },
      "source": [
        "To check the datatype of all the features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpbn0B3gAzGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89008cfd-8f67-4668-c8a2-a2880c3904db"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1599 non-null   float64\n",
            " 1   volatile acidity      1599 non-null   float64\n",
            " 2   citric acid           1599 non-null   float64\n",
            " 3   residual sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free sulfur dioxide   1599 non-null   float64\n",
            " 6   total sulfur dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz9rF1Ho2q8c"
      },
      "source": [
        "To understand the relation between various features and the quality we find the Correlation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPbSMPCC4gOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39eec9f2-7abc-487e-fdd4-27013582435e"
      },
      "source": [
        "dataset.corr()['quality']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fixed acidity           0.124052\n",
              "volatile acidity       -0.390558\n",
              "citric acid             0.226373\n",
              "residual sugar          0.013732\n",
              "chlorides              -0.128907\n",
              "free sulfur dioxide    -0.050656\n",
              "total sulfur dioxide   -0.185100\n",
              "density                -0.174919\n",
              "pH                     -0.057731\n",
              "sulphates               0.251397\n",
              "alcohol                 0.476166\n",
              "quality                 1.000000\n",
              "Name: quality, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIexdmKRApLy"
      },
      "source": [
        "Splitting the dataset into X and y:\n",
        "\n",
        "Here x are all the features and y is target. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX8EsTEVDvzc"
      },
      "source": [
        "X=dataset.iloc[:,:-1].values\n",
        "y=dataset.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqMGi3t6EbER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e735c750-8906-465a-c6b4-0441aba7c84c"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.4  ,  0.7  ,  0.   , ...,  3.51 ,  0.56 ,  9.4  ],\n",
              "       [ 7.8  ,  0.88 ,  0.   , ...,  3.2  ,  0.68 ,  9.8  ],\n",
              "       [ 7.8  ,  0.76 ,  0.04 , ...,  3.26 ,  0.65 ,  9.8  ],\n",
              "       ...,\n",
              "       [ 6.3  ,  0.51 ,  0.13 , ...,  3.42 ,  0.75 , 11.   ],\n",
              "       [ 5.9  ,  0.645,  0.12 , ...,  3.57 ,  0.71 , 10.2  ],\n",
              "       [ 6.   ,  0.31 ,  0.47 , ...,  3.39 ,  0.66 , 11.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zotrIaX0Ek1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c07a00-a957-4b03-d402-d35c1f858ef4"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, ..., 6, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7rLIoTCEswZ"
      },
      "source": [
        "Splitting the data into Test and Train Samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlQ7h65FEsZX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "460Ir_0tElkE"
      },
      "source": [
        "X_train , X_test ,y_train , y_test= train_test_split(X,y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khXRei-AI9hC"
      },
      "source": [
        "##Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDNLE0NB8i9x"
      },
      "source": [
        "Importing the library required to perform Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMW0_6JXI9Jr"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvggSrFmJXd8"
      },
      "source": [
        "mreg= LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCU2SBL-8uRV"
      },
      "source": [
        "Training the train samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65wamFk7JaQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbab5d2-3582-4abd-ccb5-b38c625aa1e1"
      },
      "source": [
        "mreg.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc2FOq_E9KWE"
      },
      "source": [
        "To predict the quality values for the Test Features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUbQKVGpJctv"
      },
      "source": [
        "pred=mreg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8ryJpVk9fVq"
      },
      "source": [
        "To view all the predicted outputs and  the difference between the predicted and real output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpdUKyfbJfKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0148ecab-ae36-4747-8611-842782b76e87"
      },
      "source": [
        "for i in range(len(X_test)):\n",
        "  print(X_test[i],y_test[i],pred[i],y_test[i]-pred[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 7.5      0.31     0.41     2.4      0.065   34.      60.       0.99492\n",
            "  3.34     0.85    11.4    ] 6 6.33623047423467 -0.3362304742346698\n",
            "[ 8.4      0.62     0.12     1.8      0.072   38.      46.       0.99504\n",
            "  3.38     0.89    11.8    ] 6 6.2610557491968635 -0.2610557491968635\n",
            "[ 5.6      0.605    0.05     2.4      0.073   19.      25.       0.99258\n",
            "  3.56     0.55    12.9    ] 5 6.2180959099299535 -1.2180959099299535\n",
            "[10.3    0.59   0.42   2.8    0.09  35.    73.     0.999  3.28   0.7\n",
            "  9.5  ] 6 5.31577150344664 0.6842284965533603\n",
            "[ 7.     0.45   0.34   2.7    0.082 16.    72.     0.998  3.55   0.6\n",
            "  9.5  ] 5 5.195489868003314 -0.19548986800331392\n",
            "[8.200e+00 6.000e-01 1.700e-01 2.300e+00 7.200e-02 1.100e+01 7.300e+01\n",
            " 9.963e-01 3.200e+00 4.500e-01 9.300e+00] 5 5.047038980918687 -0.0470389809186873\n",
            "[8.100e+00 7.850e-01 5.200e-01 2.000e+00 1.220e-01 3.700e+01 1.530e+02\n",
            " 9.969e-01 3.210e+00 6.900e-01 9.300e+00] 5 4.722320876805917 0.2776791231940834\n",
            "[9.000e+00 4.400e-01 4.900e-01 2.400e+00 7.800e-02 2.600e+01 1.210e+02\n",
            " 9.978e-01 3.230e+00 5.800e-01 9.200e+00] 5 5.118066487078705 -0.11806648707870515\n",
            "[ 8.5      0.4      0.4      6.3      0.05     3.      10.       0.99566\n",
            "  3.28     0.56    12.     ] 4 6.320312754142128 -2.320312754142128\n",
            "[ 8.2      0.26     0.34     2.5      0.073   16.      47.       0.99594\n",
            "  3.4      0.78    11.3    ] 7 6.272880628548554 0.7271193714514457\n",
            "[ 6.       0.5      0.       1.4      0.057   15.      26.       0.99448\n",
            "  3.36     0.45     9.5    ] 5 5.323549981765851 -0.3235499817658507\n",
            "[11.5     0.3     0.6     2.      0.067  12.     27.      0.9981  3.11\n",
            "  0.97   10.1   ] 6 6.202751825779479 -0.2027518257794787\n",
            "[ 8.9      0.12     0.45     1.8      0.075   10.      21.       0.99552\n",
            "  3.41     0.76    11.9    ] 7 6.618699110713532 0.381300889286468\n",
            "[6.5000e+00 8.8000e-01 3.0000e-02 5.6000e+00 7.9000e-02 2.3000e+01\n",
            " 4.7000e+01 9.9572e-01 3.5800e+00 5.0000e-01 1.1200e+01] 4 5.333467958653671 -1.3334679586536708\n",
            "[ 5.9     0.44    0.      1.6     0.042   3.     11.      0.9944  3.48\n",
            "  0.85   11.7   ] 6 6.391806000616532 -0.3918060006165316\n",
            "[ 7.      0.78    0.08    2.      0.093  10.     19.      0.9956  3.4\n",
            "  0.47   10.    ] 5 5.1190081120401265 -0.11900811204012651\n",
            "[5.400e+00 8.350e-01 8.000e-02 1.200e+00 4.600e-02 1.300e+01 9.300e+01\n",
            " 9.924e-01 3.570e+00 8.500e-01 1.300e+01] 7 6.0799315463842305 0.9200684536157695\n",
            "[ 7.8     0.52    0.25    1.9     0.081  14.     38.      0.9984  3.43\n",
            "  0.65    9.    ] 6 5.187228016116484 0.8127719838835157\n",
            "[ 7.6     0.62    0.32    2.2     0.082   7.     54.      0.9966  3.36\n",
            "  0.52    9.4   ] 5 5.0334952363871865 -0.033495236387186544\n",
            "[ 6.1      0.6      0.08     1.8      0.071   14.      45.       0.99336\n",
            "  3.38     0.54    11.     ] 5 5.644876190656616 -0.6448761906566158\n",
            "[10.2     0.42    0.57    3.4     0.07    4.     10.      0.9971  3.04\n",
            "  0.63    9.6   ] 5 5.67132745293559 -0.6713274529355902\n",
            "[11.1     0.18    0.48    1.5     0.068   7.     15.      0.9973  3.22\n",
            "  0.64   10.1   ] 6 6.030663579536233 -0.030663579536232888\n",
            "[10.1      0.37     0.34     2.4      0.085    5.      17.       0.99683\n",
            "  3.17     0.65    10.6    ] 7 5.988941147203186 1.0110588527968138\n",
            "[7.2000e+00 6.2000e-01 6.0000e-02 2.5000e+00 7.8000e-02 1.7000e+01\n",
            " 8.4000e+01 9.9746e-01 3.5100e+00 5.3000e-01 9.7000e+00] 5 5.0703793562233415 -0.07037935622334146\n",
            "[ 7.2      0.36     0.46     2.1      0.074   24.      44.       0.99534\n",
            "  3.4      0.85    11.     ] 7 6.121995759704922 0.8780042402950778\n",
            "[4.600e+00 5.200e-01 1.500e-01 2.100e+00 5.400e-02 8.000e+00 6.500e+01\n",
            " 9.934e-01 3.900e+00 5.600e-01 1.310e+01] 4 6.0810039156732785 -2.0810039156732785\n",
            "[12.5     0.46    0.63    2.      0.071   6.     15.      0.9988  2.99\n",
            "  0.87   10.2   ] 5 6.041507558052711 -1.041507558052711\n",
            "[ 6.4      0.64     0.21     1.8      0.081   14.      31.       0.99689\n",
            "  3.59     0.66     9.8    ] 5 5.252157733488083 -0.2521577334880831\n",
            "[ 6.9     0.4     0.14    2.4     0.085  21.     40.      0.9968  3.43\n",
            "  0.63    9.7   ] 6 5.531710141594772 0.4682898584052282\n",
            "[ 8.7     0.625   0.16    2.      0.101  13.     49.      0.9962  3.14\n",
            "  0.57   11.    ] 5 5.69412816245075 -0.6941281624507498\n",
            "[7.1000e+00 5.9000e-01 2.0000e-02 2.3000e+00 8.2000e-02 2.4000e+01\n",
            " 9.4000e+01 9.9744e-01 3.5500e+00 5.3000e-01 9.7000e+00] 6 5.074915306742849 0.9250846932571513\n",
            "[ 7.1      0.715    0.       2.35     0.071   21.      47.       0.99632\n",
            "  3.29     0.45     9.4    ] 5 5.043466464435701 -0.04346646443570101\n",
            "[11.5     0.18    0.51    4.      0.104   4.     23.      0.9996  3.28\n",
            "  0.97   10.1   ] 6 6.216746516342884 -0.21674651634288367\n",
            "[ 7.3     0.835   0.03    2.1     0.092  10.     19.      0.9966  3.39\n",
            "  0.47    9.6   ] 5 4.960729914575841 0.03927008542415944\n",
            "[ 8.2     0.78    0.      2.2     0.089  13.     26.      0.9978  3.37\n",
            "  0.46    9.6   ] 4 5.031064336919279 -1.031064336919279\n",
            "[11.6    0.42   0.53   3.3    0.105 33.    98.     1.001  3.2    0.95\n",
            "  9.2  ] 5 5.5521489748291035 -0.5521489748291035\n",
            "[7.900e+00 4.900e-01 3.200e-01 1.900e+00 8.200e-02 1.700e+01 1.440e+02\n",
            " 9.968e-01 3.200e+00 5.500e-01 9.500e+00] 5 5.060598221952222 -0.06059822195222164\n",
            "[11.9    0.58   0.58   1.9    0.071  5.    18.     0.998  3.09   0.63\n",
            " 10.   ] 6 5.590307152385559 0.4096928476144406\n",
            "[ 9.3      0.36     0.39     1.5      0.08    41.      55.       0.99652\n",
            "  3.47     0.73    10.9    ] 6 6.00392500439412 -0.003925004394120357\n",
            "[ 6.4     0.37    0.25    1.9     0.074  21.     49.      0.9974  3.57\n",
            "  0.62    9.8   ] 6 5.4816841951926945 0.5183158048073055\n",
            "[ 8.3     0.26    0.42    2.      0.08   11.     27.      0.9974  3.21\n",
            "  0.8     9.4   ] 6 5.806688690143581 0.1933113098564192\n",
            "[10.2      0.41     0.43     2.2      0.11    11.      37.       0.99728\n",
            "  3.16     0.67    10.8    ] 5 5.919988682754541 -0.9199886827545409\n",
            "[ 6.2      0.56     0.09     1.7      0.053   24.      32.       0.99402\n",
            "  3.54     0.6     11.3    ] 5 5.859676901323111 -0.8596769013231107\n",
            "[10.1      0.38     0.5      2.4      0.104    6.      13.       0.99643\n",
            "  3.22     0.65    11.6    ] 7 6.202745892356727 0.7972541076432726\n",
            "[ 6.8      0.61     0.04     1.5      0.057    5.      10.       0.99525\n",
            "  3.42     0.6      9.5    ] 5 5.337698231039877 -0.3376982310398766\n",
            "[ 6.6     0.8     0.03    7.8     0.079   6.     12.      0.9963  3.52\n",
            "  0.5    12.2   ] 5 5.81517065853348 -0.8151706585334804\n",
            "[7.7000e+00 5.8000e-01 1.0000e-02 1.8000e+00 8.8000e-02 1.2000e+01\n",
            " 1.8000e+01 9.9568e-01 3.3200e+00 5.6000e-01 1.0500e+01] 7 5.638351304392702 1.3616486956072977\n",
            "[6.700e+00 6.750e-01 7.000e-02 2.400e+00 8.900e-02 1.700e+01 8.200e+01\n",
            " 9.958e-01 3.350e+00 5.400e-01 1.010e+01] 5 5.1854301606520945 -0.1854301606520945\n",
            "[ 9.1     0.64    0.23    3.1     0.095  13.     38.      0.9998  3.28\n",
            "  0.59    9.7   ] 5 5.280668038596532 -0.28066803859653167\n",
            "[ 6.8     0.67    0.02    1.8     0.05    5.     11.      0.9962  3.48\n",
            "  0.52    9.5   ] 5 5.191509912049893 -0.19150991204989332\n",
            "[ 8.1     0.545   0.18    1.9     0.08   13.     35.      0.9972  3.3\n",
            "  0.59    9.    ] 6 5.19254582493915 0.8074541750608502\n",
            "[ 9.9     0.54    0.45    2.3     0.071  16.     40.      0.9991  3.39\n",
            "  0.62    9.4   ] 5 5.283416423631602 -0.2834164236316017\n",
            "[12.4     0.35    0.49    2.6     0.079  27.     69.      0.9994  3.12\n",
            "  0.75   10.4   ] 6 5.977336240147741 0.02266375985225899\n",
            "[ 6.4     0.4     0.23    1.6     0.066   5.     12.      0.9958  3.34\n",
            "  0.56    9.2   ] 5 5.395823863435693 -0.39582386343569276\n",
            "[9.300e+00 4.000e-01 4.900e-01 2.500e+00 8.500e-02 3.800e+01 1.420e+02\n",
            " 9.978e-01 3.220e+00 5.500e-01 9.400e+00] 5 5.162877508588313 -0.16287750858831274\n",
            "[10.6     0.31    0.49    2.2     0.063  18.     40.      0.9976  3.14\n",
            "  0.51    9.8   ] 6 5.678497291154234 0.3215027088457658\n",
            "[11.9     0.38    0.49    2.7     0.098  12.     42.      1.0004  3.16\n",
            "  0.61   10.3   ] 5 5.767824637177416 -0.7678246371774158\n",
            "[8.0000e+00 7.1500e-01 2.2000e-01 2.3000e+00 7.5000e-02 1.3000e+01\n",
            " 8.1000e+01 9.9688e-01 3.2400e+00 5.4000e-01 9.5000e+00] 6 5.008450570468687 0.9915494295313128\n",
            "[ 7.1      0.34     0.28     2.       0.082   31.      68.       0.99694\n",
            "  3.45     0.48     9.4    ] 5 5.282753894371937 -0.282753894371937\n",
            "[ 9.      0.53    0.49    1.9     0.171   6.     25.      0.9975  3.27\n",
            "  0.61    9.4   ] 6 5.150423495762079 0.8495765042379206\n",
            "[ 6.8      0.56     0.22     1.8      0.074   15.      24.       0.99438\n",
            "  3.4      0.82    11.2    ] 6 6.024444376149406 -0.024444376149405755\n",
            "[ 7.      0.55    0.13    2.2     0.075  15.     35.      0.9959  3.36\n",
            "  0.59    9.7   ] 6 5.3856875295728415 0.6143124704271585\n",
            "[ 8.2      1.       0.09     2.3      0.065    7.      37.       0.99685\n",
            "  3.32     0.55     9.     ] 6 4.6941738095546075 1.3058261904453925\n",
            "[ 9.4      0.395    0.46     4.6      0.094    3.      10.       0.99639\n",
            "  3.27     0.64    12.2    ] 7 6.369461258317934 0.6305387416820656\n",
            "[ 7.9      0.66     0.       1.4      0.096    6.      13.       0.99569\n",
            "  3.43     0.58     9.5    ] 5 5.212981574030852 -0.21298157403085227\n",
            "[7.100e+00 5.900e-01 1.000e-02 2.300e+00 8.000e-02 2.700e+01 4.300e+01\n",
            " 9.955e-01 3.420e+00 5.800e-01 1.070e+01] 6 5.640953406772347 0.359046593227653\n",
            "[ 5.2     0.49    0.26    2.3     0.09   23.     74.      0.9953  3.71\n",
            "  0.62   12.2   ] 6 5.906185557909675 0.0938144420903253\n",
            "[12.2     0.45    0.49    1.4     0.075   3.      6.      0.9969  3.13\n",
            "  0.63   10.4   ] 5 5.880099192264743 -0.8800991922647432\n",
            "[7.9    0.885  0.03   1.8    0.058  4.     8.     0.9972 3.36   0.33\n",
            " 9.1   ] 4 4.727291096012822 -0.7272910960128218\n",
            "[8.200e+00 5.700e-01 2.600e-01 2.200e+00 6.000e-02 2.800e+01 6.500e+01\n",
            " 9.959e-01 3.300e+00 4.300e-01 1.010e+01] 5 5.331167608748903 -0.3311676087489026\n",
            "[ 8.2      0.44     0.24     2.3      0.063   10.      28.       0.99613\n",
            "  3.25     0.53    10.2    ] 6 5.667478456395948 0.3325215436040523\n",
            "[7.50e+00 6.00e-01 3.00e-02 1.80e+00 9.50e-02 2.50e+01 9.90e+01 9.95e-01\n",
            " 3.35e+00 5.40e-01 1.01e+01] 5 5.247489375028184 -0.24748937502818436\n",
            "[ 7.7      0.39     0.12     1.7      0.097   19.      27.       0.99596\n",
            "  3.16     0.49     9.4    ] 5 5.464443839070993 -0.4644438390709933\n",
            "[7.8000e+00 8.1500e-01 1.0000e-02 2.6000e+00 7.4000e-02 4.8000e+01\n",
            " 9.0000e+01 9.9621e-01 3.3800e+00 6.2000e-01 1.0800e+01] 5 5.425732568973095 -0.4257325689730953\n",
            "[ 9.7      0.66     0.34     2.6      0.094   12.      88.       0.99796\n",
            "  3.26     0.66    10.1    ] 5 5.289123319755119 -0.2891233197551193\n",
            "[ 7.6     0.3     0.42    2.      0.052   6.     24.      0.9963  3.44\n",
            "  0.82   11.9   ] 6 6.473158751884343 -0.473158751884343\n",
            "[ 7.1      0.34     0.28     2.       0.082   31.      68.       0.99694\n",
            "  3.45     0.48     9.4    ] 5 5.282753894371937 -0.282753894371937\n",
            "[ 5.3      0.715    0.19     1.5      0.161    7.      62.       0.99395\n",
            "  3.62     0.61    11.     ] 5 5.215419391340035 -0.21541939134003485\n",
            "[11.5      0.42     0.48     2.6      0.077    8.      20.       0.99852\n",
            "  3.09     0.53    11.     ] 5 5.983041726792594 -0.9830417267925942\n",
            "[9.80e+00 9.80e-01 3.20e-01 2.30e+00 7.80e-02 3.50e+01 1.52e+02 9.98e-01\n",
            " 3.25e+00 4.80e-01 9.40e+00] 5 4.4900023693603 0.5099976306396998\n",
            "[6.900e+00 7.650e-01 2.000e-02 2.300e+00 6.300e-02 3.500e+01 6.300e+01\n",
            " 9.975e-01 3.570e+00 7.800e-01 9.900e+00] 5 5.3137670707994715 -0.3137670707994715\n",
            "[6.600e+00 7.250e-01 2.000e-01 7.800e+00 7.300e-02 2.900e+01 7.900e+01\n",
            " 9.977e-01 3.290e+00 5.400e-01 9.200e+00] 5 4.960560682521391 0.039439317478609404\n",
            "[ 6.8     0.67    0.15    1.8     0.118  13.     20.      0.9954  3.42\n",
            "  0.67   11.3   ] 6 5.736481531899158 0.263518468100842\n",
            "[6.7000e+00 8.5500e-01 2.0000e-02 1.9000e+00 6.4000e-02 2.9000e+01\n",
            " 3.8000e+01 9.9472e-01 3.3000e+00 5.6000e-01 1.0750e+01] 6 5.443175739047386 0.556824260952614\n",
            "[12.3     0.27    0.49    3.1     0.079  28.     46.      0.9993  3.2\n",
            "  0.8    10.2   ] 6 6.086981279541867 -0.08698127954186674\n",
            "[12.8     0.615   0.66    5.8     0.083   7.     42.      1.0022  3.07\n",
            "  0.73   10.    ] 7 5.578261165434331 1.4217388345656694\n",
            "[ 9.6      0.5      0.36     2.8      0.116   26.      55.       0.99722\n",
            "  3.18     0.68    10.9    ] 5 5.843105175915191 -0.8431051759151913\n",
            "[8.300e+00 8.450e-01 1.000e-02 2.200e+00 7.000e-02 5.000e+00 1.400e+01\n",
            " 9.967e-01 3.320e+00 5.800e-01 1.100e+01] 4 5.55802808869028 -1.5580280886902802\n",
            "[7.000e+00 6.500e-01 2.000e-02 2.100e+00 6.600e-02 8.000e+00 2.500e+01\n",
            " 9.972e-01 3.470e+00 6.700e-01 9.500e+00] 6 5.292208488199616 0.7077915118003837\n",
            "[6.6000e+00 8.5500e-01 2.0000e-02 2.4000e+00 6.2000e-02 1.5000e+01\n",
            " 2.3000e+01 9.9627e-01 3.5400e+00 6.0000e-01 1.1000e+01] 6 5.46239793712472 0.5376020628752798\n",
            "[8.8000e+00 3.0000e-01 3.8000e-01 2.3000e+00 6.0000e-02 1.9000e+01\n",
            " 7.2000e+01 9.9543e-01 3.3900e+00 7.2000e-01 1.1800e+01] 6 6.2898093527913925 -0.2898093527913925\n",
            "[8.6000e+00 2.2000e-01 3.6000e-01 1.9000e+00 6.4000e-02 5.3000e+01\n",
            " 7.7000e+01 9.9604e-01 3.4700e+00 8.7000e-01 1.1000e+01] 7 6.304307591955675 0.6956924080443248\n",
            "[ 7.6     0.55    0.21    2.2     0.071   7.     28.      0.9964  3.28\n",
            "  0.55    9.7   ] 5 5.378712373596187 -0.37871237359618704\n",
            "[ 9.1     0.45    0.35    2.4     0.08   23.     78.      0.9987  3.38\n",
            "  0.62    9.5   ] 5 5.316813389820758 -0.3168133898207577\n",
            "[ 6.2      0.7      0.15     5.1      0.076   13.      27.       0.99622\n",
            "  3.54     0.6     11.9    ] 6 5.839227155444693 0.16077284455530716\n",
            "[8.6000e+00 7.2500e-01 2.4000e-01 6.6000e+00 1.1700e-01 3.1000e+01\n",
            " 1.3400e+02 1.0014e+00 3.3200e+00 1.0700e+00 9.3000e+00] 5 5.222061466934976 -0.22206146693497608\n",
            "[ 8.      0.38    0.44    1.9     0.098   6.     15.      0.9956  3.3\n",
            "  0.64   11.4   ] 6 6.082933510672131 -0.08293351067213095\n",
            "[6.500e+00 3.900e-01 2.300e-01 8.300e+00 5.100e-02 2.800e+01 9.100e+01\n",
            " 9.952e-01 3.440e+00 5.500e-01 1.210e+01] 6 6.138077235505543 -0.13807723550554307\n",
            "[8.200e+00 5.600e-01 2.300e-01 3.400e+00 7.800e-02 1.400e+01 1.040e+02\n",
            " 9.976e-01 3.280e+00 6.200e-01 9.400e+00] 5 5.136178375346612 -0.1361783753466117\n",
            "[ 8.9      0.5      0.21     2.2      0.088   21.      39.       0.99692\n",
            "  3.33     0.83    11.1    ] 6 6.077117432595374 -0.07711743259537407\n",
            "[ 6.6     0.52    0.04    2.2     0.069   8.     15.      0.9956  3.4\n",
            "  0.63    9.4   ] 6 5.411772347027112 0.588227652972888\n",
            "[ 9.3     0.775   0.27    2.8     0.078  24.     56.      0.9984  3.31\n",
            "  0.67   10.6   ] 6 5.469121578574901 0.5308784214250988\n",
            "[10.9      0.37     0.58     4.       0.071   17.      65.       0.99935\n",
            "  3.22     0.78    10.1    ] 5 5.815220954139782 -0.8152209541397824\n",
            "[ 6.8      0.81     0.05     2.       0.07     6.      14.       0.99562\n",
            "  3.51     0.66    10.8    ] 6 5.499030754552569 0.5009692454474308\n",
            "[ 7.9      0.33     0.23     1.7      0.077   18.      45.       0.99625\n",
            "  3.29     0.65     9.3    ] 5 5.545467455395221 -0.5454674553952206\n",
            "[ 6.2      0.57     0.1      2.1      0.048    4.      11.       0.99448\n",
            "  3.44     0.76    10.8    ] 6 5.897436409396946 0.10256359060305442\n",
            "[7.30000000e+00 6.70000000e-01 2.00000000e-02 2.20000000e+00\n",
            " 7.20000000e-02 3.10000000e+01 9.20000000e+01 9.95660000e-01\n",
            " 3.32000000e+00 6.80000000e-01 1.10666667e+01] 6 5.677175949477853 0.32282405052214713\n",
            "[ 7.2    0.41   0.3    2.1    0.083 35.    72.     0.997  3.44   0.52\n",
            "  9.4  ] 5 5.243009089413072 -0.2430090894130723\n",
            "[ 9.3      0.655    0.26     2.       0.096    5.      35.       0.99738\n",
            "  3.25     0.42     9.6    ] 5 5.07583064861233 -0.07583064861232991\n",
            "[ 8.7     0.69    0.31    3.      0.086  23.     81.      1.0002  3.48\n",
            "  0.74   11.6   ] 6 5.739320333266846 0.2606796667331537\n",
            "[ 9.6     0.6     0.5     2.3     0.079  28.     71.      0.9997  3.5\n",
            "  0.57    9.7   ] 5 5.129653102633631 -0.12965310263363072\n",
            "[ 6.9      0.765    0.18     2.4      0.243    5.5     48.       0.99612\n",
            "  3.4      0.6     10.3    ] 6 4.9543634131074565 1.0456365868925435\n",
            "[7.80e+00 5.00e-01 1.70e-01 1.60e+00 8.20e-02 2.10e+01 1.02e+02 9.96e-01\n",
            " 3.39e+00 4.80e-01 9.50e+00] 5 5.076517037080333 -0.07651703708033342\n",
            "[ 9.4     0.41    0.48    4.6     0.072  10.     20.      0.9973  3.34\n",
            "  0.79   12.2   ] 7 6.480317677571453 0.5196823224285474\n",
            "[8.700e+00 8.200e-01 2.000e-02 1.200e+00 7.000e-02 3.600e+01 4.800e+01\n",
            " 9.952e-01 3.200e+00 5.800e-01 9.800e+00] 5 5.260965214887876 -0.26096521488787605\n",
            "[ 6.8      0.62     0.08     1.9      0.068   28.      38.       0.99651\n",
            "  3.42     0.82     9.5    ] 6 5.474890729638993 0.525109270361007\n",
            "[ 5.7    1.13   0.09   1.5    0.172  7.    19.     0.994  3.5    0.48\n",
            "  9.8  ] 4 4.4821694325187735 -0.48216943251877353\n",
            "[10.4     0.64    0.24    2.8     0.105  29.     53.      0.9998  3.24\n",
            "  0.67    9.9   ] 5 5.427888764605196 -0.4278887646051963\n",
            "[7.1000e+00 5.9000e-01 1.0000e-02 2.5000e+00 7.7000e-02 2.0000e+01\n",
            " 8.5000e+01 9.9746e-01 3.5500e+00 5.9000e-01 9.8000e+00] 5 5.186303946810719 -0.18630394681071927\n",
            "[ 7.2     0.52    0.07    1.4     0.074   5.     20.      0.9973  3.32\n",
            "  0.81    9.6   ] 6 5.625355553844566 0.37464444615543435\n",
            "[10.4     0.61    0.49    2.1     0.2     5.     16.      0.9994  3.16\n",
            "  0.63    8.4   ] 3 4.81998166374533 -1.81998166374533\n",
            "[7.1000e+00 7.5000e-01 1.0000e-02 2.2000e+00 5.9000e-02 1.1000e+01\n",
            " 1.8000e+01 9.9242e-01 3.3900e+00 4.0000e-01 1.2800e+01] 6 6.026094306639441 -0.026094306639440568\n",
            "[6.600e+00 8.400e-01 3.000e-02 2.300e+00 5.900e-02 3.200e+01 4.800e+01\n",
            " 9.952e-01 3.520e+00 5.600e-01 1.230e+01] 7 5.81928996297073 1.1807100370292698\n",
            "[ 6.4      0.56     0.15     1.8      0.078   17.      65.       0.99294\n",
            "  3.33     0.6     10.5    ] 6 5.5391824129194696 0.46081758708053044\n",
            "[11.1      0.44     0.42     2.2      0.064   14.      19.       0.99758\n",
            "  3.25     0.57    10.4    ] 6 5.801428149586151 0.19857185041384895\n",
            "[ 7.1      0.67     0.       2.3      0.083   18.      27.       0.99768\n",
            "  3.44     0.54     9.4    ] 5 5.135082737676774 -0.1350827376767736\n",
            "[10.2     0.24    0.49    2.4     0.075  10.     28.      0.9978  3.14\n",
            "  0.61   10.4   ] 5 6.008055525731132 -1.008055525731132\n",
            "[ 7.3     0.58    0.3     2.4     0.074  15.     55.      0.9968  3.46\n",
            "  0.59   10.2   ] 5 5.371033625403822 -0.3710336254038218\n",
            "[ 8.4     0.56    0.08    2.1     0.105  16.     44.      0.9958  3.13\n",
            "  0.52   11.    ] 5 5.753867889083672 -0.7538678890836721\n",
            "[10.7    0.4    0.48   2.1    0.125 15.    49.     0.998  3.03   0.81\n",
            "  9.7  ] 6 5.7222966782094 0.2777033217906002\n",
            "[ 7.     0.62   0.1    1.4    0.071 27.    63.     0.996  3.28   0.61\n",
            "  9.2  ] 5 5.170371534202138 -0.1703715342021379\n",
            "[ 7.9     0.24    0.4     1.6     0.056  11.     25.      0.9967  3.32\n",
            "  0.87    8.7   ] 6 5.681050531656963 0.31894946834303717\n",
            "[ 7.5     0.53    0.06    2.6     0.086  20.     44.      0.9965  3.38\n",
            "  0.59   10.7   ] 6 5.692085940418076 0.30791405958192364\n",
            "[ 8.1      0.73     0.       2.5      0.081   12.      24.       0.99798\n",
            "  3.38     0.46     9.6    ] 4 5.097645211592078 -1.097645211592078\n",
            "[ 8.1    0.78   0.23   2.6    0.059  5.    15.     0.997  3.37   0.56\n",
            " 11.3  ] 5 5.643977578276045 -0.6439775782760453\n",
            "[ 7.6      0.43     0.29     2.1      0.075   19.      66.       0.99718\n",
            "  3.4      0.64     9.5    ] 5 5.371328512275446 -0.37132851227544617\n",
            "[7.000e+00 5.800e-01 1.200e-01 1.900e+00 9.100e-02 3.400e+01 1.240e+02\n",
            " 9.956e-01 3.440e+00 4.800e-01 1.050e+01] 5 5.2270753439645805 -0.2270753439645805\n",
            "[13.7     0.415   0.68    2.9     0.085  17.     43.      1.0014  3.06\n",
            "  0.8    10.    ] 6 5.870115244331366 0.129884755668634\n",
            "[ 7.9     0.6     0.06    1.6     0.069  15.     59.      0.9964  3.3\n",
            "  0.46    9.4   ] 5 5.116885707429207 -0.11688570742920668\n",
            "[ 9.1      0.21     0.37     1.6      0.067    6.      10.       0.99552\n",
            "  3.23     0.58    11.1    ] 7 6.251674195885535 0.7483258041144651\n",
            "[12.4     0.42    0.49    4.6     0.073  19.     43.      0.9978  3.02\n",
            "  0.61    9.5   ] 5 5.633506534970579 -0.6335065349705786\n",
            "[ 5.9      0.645    0.12     2.       0.075   32.      44.       0.99547\n",
            "  3.57     0.71    10.2    ] 5 5.459122382397682 -0.4591223823976822\n",
            "[ 7.4      0.965    0.       2.2      0.088   16.      32.       0.99756\n",
            "  3.58     0.67    10.2    ] 5 5.094605478859967 -0.09460547885996728\n",
            "[ 9.3      0.43     0.44     1.9      0.085    9.      22.       0.99708\n",
            "  3.28     0.55     9.5    ] 5 5.4168089487063815 -0.4168089487063815\n",
            "[11.5     0.315   0.54    2.1     0.084   5.     15.      0.9987  2.98\n",
            "  0.7     9.2   ] 6 5.728036034523878 0.27196396547612167\n",
            "[ 8.9      0.12     0.45     1.8      0.075   10.      21.       0.99552\n",
            "  3.41     0.76    11.9    ] 7 6.618699110713532 0.381300889286468\n",
            "[11.8     0.38    0.55    2.1     0.071   5.     19.      0.9986  3.11\n",
            "  0.62   10.8   ] 6 6.028221988306585 -0.02822198830658529\n",
            "[ 8.9     0.875   0.13    3.45    0.088   4.     14.      0.9994  3.44\n",
            "  0.52   11.5   ] 5 5.522949942362205 -0.5229499423622048\n",
            "[10.5     0.24    0.42    1.8     0.077   6.     22.      0.9976  3.21\n",
            "  1.05   10.8   ] 7 6.511634884711853 0.48836511528814697\n",
            "[7.4000e+00 6.0000e-01 2.6000e-01 2.1000e+00 8.3000e-02 1.7000e+01\n",
            " 9.1000e+01 9.9616e-01 3.2900e+00 5.6000e-01 9.8000e+00] 6 5.167200735870075 0.8327992641299247\n",
            "[ 9.1      0.37     0.32     2.1      0.064    4.      15.       0.99576\n",
            "  3.3      0.8     11.2    ] 6 6.278219051981376 -0.27821905198137564\n",
            "[8.100e+00 6.600e-01 7.000e-01 2.200e+00 9.800e-02 2.500e+01 1.290e+02\n",
            " 9.972e-01 3.080e+00 5.300e-01 9.000e+00] 5 4.715502467162458 0.2844975328375421\n",
            "[ 6.7     0.46    0.24    1.7     0.077  18.     34.      0.9948  3.39\n",
            "  0.6    10.6   ] 6 5.724767101526058 0.2752328984739423\n",
            "[ 6.6      0.895    0.04     2.3      0.068    7.      13.       0.99582\n",
            "  3.53     0.58    10.8    ] 6 5.338727944848417 0.6612720551515832\n",
            "[ 8.3      1.02     0.02     3.4      0.084    6.      11.       0.99892\n",
            "  3.48     0.49    11.     ] 3 5.212860942320265 -2.2128609423202654\n",
            "[10.4     0.33    0.63    2.8     0.084   5.     22.      0.9998  3.26\n",
            "  0.74   11.2   ] 7 6.175043972273976 0.8249560277260244\n",
            "[6.7000e+00 6.7000e-01 2.0000e-02 1.9000e+00 6.1000e-02 2.6000e+01\n",
            " 4.2000e+01 9.9489e-01 3.3900e+00 8.2000e-01 1.0900e+01] 6 5.865278450001217 0.13472154999878327\n",
            "[ 6.       0.5      0.04     2.2      0.092   13.      26.       0.99647\n",
            "  3.46     0.47    10.     ] 5 5.373859350217174 -0.37385935021717387\n",
            "[ 6.5      0.53     0.06     2.       0.063   29.      44.       0.99489\n",
            "  3.38     0.83    10.3    ] 6 5.834828647192122 0.16517135280787798\n",
            "[ 7.       0.57     0.       2.       0.19    12.      45.       0.99676\n",
            "  3.31     0.6      9.4    ] 6 5.088040641699269 0.9119593583007308\n",
            "[ 8.4     0.745   0.11    1.9     0.09   16.     63.      0.9965  3.19\n",
            "  0.82    9.6   ] 5 5.340618235167199 -0.3406182351671987\n",
            "[10.7      0.52     0.38     2.6      0.066   29.      56.       0.99577\n",
            "  3.15     0.79    12.1    ] 7 6.402338417979253 0.5976615820207467\n",
            "[10.9     0.39    0.47    1.8     0.118   6.     14.      0.9982  3.3\n",
            "  0.75    9.8   ] 6 5.692219428704569 0.3077805712954307\n",
            "[ 8.5      0.37     0.32     1.8      0.066   26.      51.       0.99456\n",
            "  3.38     0.72    11.8    ] 6 6.296613213132373 -0.2966132131323729\n",
            "[7.2000e+00 6.2000e-01 6.0000e-02 2.7000e+00 7.7000e-02 1.5000e+01\n",
            " 8.5000e+01 9.9746e-01 3.5100e+00 5.4000e-01 9.5000e+00] 5 5.014239583608578 -0.014239583608578243\n",
            "[ 7.3      0.74     0.08     1.7      0.094   10.      45.       0.99576\n",
            "  3.24     0.5      9.8    ] 5 5.118321665667052 -0.11832166566705205\n",
            "[ 9.2      0.46     0.23     2.6      0.091   18.      77.       0.99922\n",
            "  3.15     0.51     9.4    ] 5 5.270880876567731 -0.2708808765677313\n",
            "[ 7.2      0.57     0.05     2.3      0.081   16.      36.       0.99564\n",
            "  3.38     0.6     10.3    ] 6 5.557257833897806 0.4427421661021942\n",
            "[9.80e+00 1.24e+00 3.40e-01 2.00e+00 7.90e-02 3.20e+01 1.51e+02 9.98e-01\n",
            " 3.15e+00 5.30e-01 9.50e+00] 5 4.314155010278295 0.6858449897217049\n",
            "[ 7.2      0.57     0.05     2.3      0.081   16.      36.       0.99564\n",
            "  3.38     0.6     10.3    ] 6 5.557257833897806 0.4427421661021942\n",
            "[ 8.9     0.32    0.31    2.      0.088  12.     19.      0.9957  3.17\n",
            "  0.55   10.4   ] 6 5.888085357685833 0.11191464231416681\n",
            "[ 8.6      0.33     0.4      2.6      0.083   16.      68.       0.99782\n",
            "  3.3      0.48     9.4    ] 5 5.311601023012414 -0.31160102301241377\n",
            "[ 7.2      0.695    0.13     2.       0.076   12.      20.       0.99546\n",
            "  3.29     0.54    10.1    ] 5 5.37193916760277 -0.3719391676027701\n",
            "[7.900e+00 3.500e-01 2.100e-01 1.900e+00 7.300e-02 4.600e+01 1.020e+02\n",
            " 9.964e-01 3.270e+00 5.800e-01 9.500e+00] 5 5.4526458913902065 -0.4526458913902065\n",
            "[ 9.6      0.41     0.37     2.3      0.091   10.      23.       0.99786\n",
            "  3.24     0.56    10.5    ] 5 5.773997367939927 -0.773997367939927\n",
            "[ 8.1      0.82     0.       4.1      0.095    5.      14.       0.99854\n",
            "  3.36     0.53     9.6    ] 5 5.067815900610182 -0.06781590061018239\n",
            "[ 9.5      0.86     0.26     1.9      0.079   13.      28.       0.99712\n",
            "  3.25     0.62    10.     ] 5 5.231223706343375 -0.23122370634337486\n",
            "[ 6.4      0.57     0.12     2.3      0.12    25.      36.       0.99519\n",
            "  3.47     0.71    11.3    ] 7 5.845380493264576 1.1546195067354237\n",
            "[10.      0.49    0.2    11.      0.071  13.     50.      1.0015  3.16\n",
            "  0.69    9.2   ] 6 5.51288891182827 0.48711108817173\n",
            "[10.9     0.39    0.47    1.8     0.118   6.     14.      0.9982  3.3\n",
            "  0.75    9.8   ] 6 5.692219428704569 0.3077805712954307\n",
            "[ 7.3      0.91     0.1      1.8      0.074   20.      56.       0.99672\n",
            "  3.35     0.56     9.2    ] 5 4.789946386849813 0.2100536131501869\n",
            "[ 7.8      0.91     0.07     1.9      0.058   22.      47.       0.99525\n",
            "  3.51     0.43    10.7    ] 6 5.138781093954063 0.861218906045937\n",
            "[7.2000e+00 6.1000e-01 8.0000e-02 4.0000e+00 8.2000e-02 2.6000e+01\n",
            " 1.0800e+02 9.9641e-01 3.2500e+00 5.1000e-01 9.4000e+00] 5 5.036558660472578 -0.036558660472578275\n",
            "[8.800e+00 4.700e-01 4.900e-01 2.900e+00 8.500e-02 1.700e+01 1.100e+02\n",
            " 9.982e-01 3.290e+00 6.000e-01 9.800e+00] 5 5.253476667079254 -0.2534766670792541\n",
            "[ 7.8     0.59    0.18    2.3     0.076  17.     54.      0.9975  3.43\n",
            "  0.59   10.    ] 5 5.350689711676518 -0.35068971167651775\n",
            "[ 7.3      0.49     0.1      2.6      0.068    4.      14.       0.99562\n",
            "  3.3      0.47    10.5    ] 5 5.666363338155093 -0.6663633381550929\n",
            "[ 7.4      0.64     0.17     5.4      0.168   52.      98.       0.99736\n",
            "  3.28     0.5      9.5    ] 5 4.951792669487933 0.04820733051206716\n",
            "[ 8.      0.42    0.17    2.      0.073   6.     18.      0.9972  3.29\n",
            "  0.61    9.2   ] 6 5.451968893376847 0.5480311066231529\n",
            "[ 6.6     0.705   0.07    1.6     0.076   6.     15.      0.9962  3.44\n",
            "  0.58   10.7   ] 5 5.512093047485507 -0.5120930474855072\n",
            "[5.600e+00 5.000e-01 9.000e-02 2.300e+00 4.900e-02 1.700e+01 9.900e+01\n",
            " 9.937e-01 3.630e+00 6.300e-01 1.300e+01] 5 6.210323581243028 -1.2103235812430277\n",
            "[ 8.5      0.44     0.5      1.9      0.369   15.      38.       0.99634\n",
            "  3.01     1.1      9.4    ] 5 5.417085134940828 -0.41708513494082844\n",
            "[10.7     0.35    0.53    2.6     0.07    5.     16.      0.9972  3.15\n",
            "  0.65   11.    ] 8 6.134891584763178 1.865108415236822\n",
            "[ 9.9      0.27     0.49     5.       0.082    9.      17.       0.99484\n",
            "  3.19     0.52    12.5    ] 7 6.5447258620624 0.4552741379376002\n",
            "[ 7.1      0.69     0.04     2.1      0.068   19.      27.       0.99712\n",
            "  3.44     0.67     9.8    ] 5 5.36976749710632 -0.36976749710632006\n",
            "[ 8.3      0.65     0.1      2.9      0.089   17.      40.       0.99803\n",
            "  3.29     0.55     9.5    ] 5 5.2059887512646466 -0.20598875126464655\n",
            "[12.5     0.56    0.49    2.4     0.064   5.     27.      0.9999  3.08\n",
            "  0.87   10.9   ] 5 6.114329308877489 -1.1143293088774886\n",
            "[9.0000e+00 6.0000e-01 2.9000e-01 2.0000e+00 6.9000e-02 3.2000e+01\n",
            " 7.3000e+01 9.9654e-01 3.3400e+00 5.7000e-01 1.0000e+01] 5 5.352547150045536 -0.3525471500455364\n",
            "[7.900e+00 6.900e-01 2.100e-01 2.100e+00 8.000e-02 3.300e+01 1.410e+02\n",
            " 9.962e-01 3.250e+00 5.100e-01 9.900e+00] 5 4.995710250756504 0.004289749243495677\n",
            "[ 6.1     0.4     0.16    1.8     0.069  11.     25.      0.9955  3.42\n",
            "  0.74   10.1   ] 7 5.779666841815143 1.2203331581848573\n",
            "[ 7.9      0.33     0.41     1.5      0.056    6.      35.       0.99396\n",
            "  3.29     0.71    11.     ] 6 6.105848922231055 -0.10584892223105502\n",
            "[ 8.2      0.35     0.33     2.4      0.076   11.      47.       0.99599\n",
            "  3.27     0.81    11.     ] 6 6.149167778449256 -0.14916777844925644\n",
            "[ 8.7     0.54    0.26    2.5     0.097   7.     31.      0.9976  3.27\n",
            "  0.6     9.3   ] 6 5.269185814921391 0.730814185078609\n",
            "[7.2000e+00 6.6000e-01 3.3000e-01 2.5000e+00 6.8000e-02 3.4000e+01\n",
            " 1.0200e+02 9.9414e-01 3.2700e+00 7.8000e-01 1.2800e+01] 6 6.2367732801544795 -0.23677328015447952\n",
            "[7.000e+00 7.350e-01 5.000e-02 2.000e+00 8.100e-02 1.300e+01 5.400e+01\n",
            " 9.966e-01 3.390e+00 5.700e-01 9.800e+00] 5 5.131399226133621 -0.1313992261336212\n",
            "[7.4000e+00 7.8500e-01 1.9000e-01 5.2000e+00 9.4000e-02 1.9000e+01\n",
            " 9.8000e+01 9.9713e-01 3.1600e+00 5.2000e-01 9.6000e+00] 6 4.929382524660797 1.070617475339203\n",
            "[13.4     0.27    0.62    2.6     0.082   6.     21.      1.0002  3.16\n",
            "  0.67    9.7   ] 6 5.8276184536857 0.17238154631430014\n",
            "[10.5    0.42   0.66   2.95   0.116 12.    29.     0.997  3.24   0.75\n",
            " 11.7  ] 7 6.191973480872662 0.8080265191273384\n",
            "[ 8.1     0.725   0.22    2.2     0.072  11.     41.      0.9967  3.36\n",
            "  0.55    9.1   ] 5 4.956148072694216 0.043851927305784244\n",
            "[ 7.7     0.18    0.34    2.7     0.066  15.     58.      0.9947  3.37\n",
            "  0.78   11.8   ] 6 6.494410263428383 -0.49441026342838335\n",
            "[6.3000e+00 5.7000e-01 2.8000e-01 2.1000e+00 4.8000e-02 1.3000e+01\n",
            " 4.9000e+01 9.9374e-01 3.4100e+00 6.0000e-01 1.2800e+01] 5 6.242520503436818 -1.2425205034368183\n",
            "[9.200e+00 9.200e-01 2.400e-01 2.600e+00 8.700e-02 1.200e+01 9.300e+01\n",
            " 9.998e-01 3.480e+00 5.400e-01 9.800e+00] 5 4.73215733040232 0.2678426695976803\n",
            "[12.6     0.39    0.49    2.5     0.08    8.     20.      0.9992  3.07\n",
            "  0.82   10.3   ] 6 6.08014926893849 -0.08014926893848973\n",
            "[ 7.3    0.695  0.     2.5    0.075  3.    13.     0.998  3.49   0.52\n",
            "  9.2  ] 5 5.028259962731897 -0.028259962731897126\n",
            "[7.1000e+00 6.0000e-01 1.0000e-02 2.3000e+00 7.9000e-02 2.4000e+01\n",
            " 3.7000e+01 9.9514e-01 3.4000e+00 6.1000e-01 1.0900e+01] 6 5.737251607484491 0.2627483925155092\n",
            "[ 7.1     0.71    0.      1.9     0.08   14.     35.      0.9972  3.47\n",
            "  0.55    9.4   ] 5 5.058458813724805 -0.05845881372480477\n",
            "[10.4      0.38     0.46     2.1      0.104    6.      10.       0.99664\n",
            "  3.12     0.65    11.8    ] 7 6.323615410149163 0.6763845898508372\n",
            "[ 6.9      0.41     0.31     2.       0.079   21.      51.       0.99668\n",
            "  3.47     0.55     9.5    ] 6 5.310416808954584 0.6895831910454158\n",
            "[ 6.5      0.58     0.       2.2      0.096    3.      13.       0.99557\n",
            "  3.62     0.62    11.5    ] 4 5.830099488544283 -1.830099488544283\n",
            "[ 7.2      0.645    0.       1.9      0.097   15.      39.       0.99675\n",
            "  3.37     0.58     9.2    ] 6 5.099270097930029 0.9007299020699708\n",
            "[ 6.8      0.67     0.       1.9      0.08    22.      39.       0.99701\n",
            "  3.4      0.74     9.7    ] 5 5.394574014859903 -0.39457401485990307\n",
            "[9.500e+00 8.850e-01 2.700e-01 2.300e+00 8.400e-02 3.100e+01 1.450e+02\n",
            " 9.978e-01 3.240e+00 5.300e-01 9.400e+00] 5 4.645762081417576 0.3542379185824238\n",
            "[7.900e+00 5.000e-01 3.300e-01 2.000e+00 8.400e-02 1.500e+01 1.430e+02\n",
            " 9.968e-01 3.200e+00 5.500e-01 9.500e+00] 5 5.042291060434115 -0.042291060434115124\n",
            "[10.9      0.32     0.52     1.8      0.132   17.      44.       0.99734\n",
            "  3.28     0.77    11.5    ] 6 6.210836156123202 -0.21083615612320195\n",
            "[12.      0.28    0.49    1.9     0.074  10.     21.      0.9976  2.98\n",
            "  0.66    9.9   ] 7 5.974951749233108 1.0250482507668917\n",
            "[ 6.2      0.39     0.43     2.       0.071   14.      24.       0.99428\n",
            "  3.45     0.87    11.2    ] 7 6.176030492514737 0.8239695074852627\n",
            "[  9.2      0.755    0.18     2.2      0.148   10.     103.       0.9969\n",
            "   2.87     1.36    10.2   ] 6 5.883783349988466 0.11621665001153403\n",
            "[ 8.8     0.6     0.29    2.2     0.098   5.     15.      0.9988  3.36\n",
            "  0.49    9.1   ] 5 5.039141016263571 -0.039141016263570805\n",
            "[ 8.3     0.66    0.15    1.9     0.079  17.     42.      0.9972  3.31\n",
            "  0.54    9.6   ] 6 5.203563681220009 0.7964363187799908\n",
            "[7.2000e+00 6.3500e-01 7.0000e-02 2.6000e+00 7.7000e-02 1.6000e+01\n",
            " 8.6000e+01 9.9748e-01 3.5100e+00 5.4000e-01 9.7000e+00] 5 5.054884252582195 -0.05488425258219465\n",
            "[ 9.      0.45    0.49    2.6     0.084  21.     75.      0.9987  3.35\n",
            "  0.57    9.7   ] 5 5.308374381659277 -0.3083743816592772\n",
            "[ 7.8     0.645   0.      5.5     0.086   5.     18.      0.9986  3.4\n",
            "  0.55    9.6   ] 6 5.265477611920207 0.7345223880797933\n",
            "[ 8.8      0.24     0.35     1.7      0.055   13.      27.       0.99394\n",
            "  3.14     0.59    11.3    ] 7 6.320855563812859 0.6791444361871406\n",
            "[ 8.2      0.28     0.4      2.4      0.052    4.      10.       0.99356\n",
            "  3.33     0.7     12.8    ] 7 6.763253241354409 0.23674675864559092\n",
            "[ 7.       0.69     0.07     2.5      0.091   15.      21.       0.99572\n",
            "  3.38     0.6     11.3    ] 6 5.745589657670549 0.25441034232945103\n",
            "[ 8.       0.64     0.22     2.4      0.094    5.      33.       0.99612\n",
            "  3.37     0.58    11.     ] 5 5.608132957534647 -0.6081329575346466\n",
            "[10.2      0.54     0.37    15.4      0.214   55.      95.       1.00369\n",
            "  3.18     0.77     9.     ] 6 5.183689353305001 0.8163106466949994\n",
            "[ 6.4     0.36    0.53    2.2     0.23   19.     35.      0.9934  3.37\n",
            "  0.93   12.4   ] 6 6.3376399882050976 -0.33763998820509755\n",
            "[10.      0.58    0.22    1.9     0.08    9.     32.      0.9974  3.13\n",
            "  0.55    9.5   ] 5 5.358970320504534 -0.35897032050453426\n",
            "[10.       0.26     0.54     1.9      0.083   42.      74.       0.99451\n",
            "  2.98     0.63    11.8    ] 8 6.419265911182018 1.580734088817982\n",
            "[6.800e+00 5.600e-01 3.000e-02 1.700e+00 8.400e-02 1.800e+01 3.500e+01\n",
            " 9.968e-01 3.440e+00 6.300e-01 1.000e+01] 6 5.473299313182359 0.5267006868176409\n",
            "[8.600e+00 4.700e-01 3.000e-01 3.000e+00 7.600e-02 3.000e+01 1.350e+02\n",
            " 9.976e-01 3.300e+00 5.300e-01 9.400e+00] 5 5.088277219433767 -0.08827721943376687\n",
            "[ 8.6      0.52     0.38     1.5      0.096    5.      18.       0.99666\n",
            "  3.2      0.52     9.4    ] 5 5.278110922800164 -0.27811092280016414\n",
            "[7.600e+00 6.450e-01 3.000e-02 1.900e+00 8.600e-02 1.400e+01 5.700e+01\n",
            " 9.969e-01 3.370e+00 4.600e-01 1.030e+01] 5 5.285527764084616 -0.2855277640846161\n",
            "[7.700e+00 2.300e-01 3.700e-01 1.800e+00 4.600e-02 2.300e+01 6.000e+01\n",
            " 9.971e-01 3.410e+00 7.100e-01 1.210e+01] 6 6.4832271448946885 -0.48322714489468854\n",
            "[13.3     0.29    0.75    2.8     0.084  23.     43.      0.9986  3.04\n",
            "  0.68   11.4   ] 7 6.326921195221269 0.673078804778731\n",
            "[ 8.8     0.61    0.14    2.4     0.067  10.     42.      0.9969  3.19\n",
            "  0.59    9.5   ] 5 5.337931854563392 -0.3379318545633918\n",
            "[12.      0.37    0.76    4.2     0.066   7.     38.      1.0004  3.22\n",
            "  0.6    13.    ] 7 6.559979829973324 0.4400201700266759\n",
            "[ 7.1      0.43     0.17     1.8      0.082   27.      51.       0.99634\n",
            "  3.49     0.64    10.4    ] 5 5.6768238452983635 -0.6768238452983635\n",
            "[10.2     0.67    0.39    1.9     0.054   6.     17.      0.9976  3.17\n",
            "  0.47   10.    ] 5 5.370843681363366 -0.37084368136336643\n",
            "[6.9000e+00 5.8000e-01 1.0000e-02 1.9000e+00 8.0000e-02 4.0000e+01\n",
            " 5.4000e+01 9.9683e-01 3.4000e+00 7.3000e-01 9.7000e+00] 5 5.4870259942515345 -0.4870259942515345\n",
            "[ 9.2      0.36     0.34     1.6      0.062    5.      12.       0.99667\n",
            "  3.2      0.67    10.5    ] 6 6.009883084747239 -0.009883084747238868\n",
            "[ 9.5     0.735   0.1     2.1     0.079   6.     31.      0.9986  3.23\n",
            "  0.56   10.1   ] 6 5.35506209214236 0.6449379078576403\n",
            "[1.060e+01 1.025e+00 4.300e-01 2.800e+00 8.000e-02 2.100e+01 8.400e+01\n",
            " 9.985e-01 3.060e+00 5.700e-01 1.010e+01] 5 4.957043349098755 0.04295665090124512\n",
            "[11.5     0.18    0.51    4.      0.104   4.     23.      0.9996  3.28\n",
            "  0.97   10.1   ] 6 6.216746516342884 -0.21674651634288367\n",
            "[10.3     0.32    0.45    6.4     0.073   5.     13.      0.9976  3.23\n",
            "  0.82   12.6   ] 8 6.80749686404096 1.19250313595904\n",
            "[ 7.4     0.63    0.07    2.4     0.09   11.     37.      0.9979  3.43\n",
            "  0.76    9.7   ] 6 5.3960672187309076 0.6039327812690924\n",
            "[7.3000e+00 5.9000e-01 2.6000e-01 2.0000e+00 8.0000e-02 1.7000e+01\n",
            " 1.0400e+02 9.9584e-01 3.2800e+00 5.2000e-01 9.9000e+00] 5 5.142062803992943 -0.14206280399294258\n",
            "[10.8     0.26    0.45    3.3     0.06   20.     49.      0.9972  3.13\n",
            "  0.54    9.6   ] 5 5.709163341289904 -0.7091633412899041\n",
            "[8.500e+00 2.800e-01 5.600e-01 1.800e+00 9.200e-02 3.500e+01 1.030e+02\n",
            " 9.969e-01 3.300e+00 7.500e-01 1.050e+01] 7 5.8271921366457065 1.1728078633542935\n",
            "[ 9.9     0.25    0.46    1.7     0.062  26.     42.      0.9959  3.18\n",
            "  0.83   10.6   ] 6 6.2650660400903835 -0.2650660400903835\n",
            "[ 7.3      0.43     0.24     2.5      0.078   27.      67.       0.99648\n",
            "  3.6      0.59    11.1    ] 6 5.749638986018724 0.2503610139812764\n",
            "[7.100e+00 6.850e-01 3.500e-01 2.000e+00 8.800e-02 9.000e+00 9.200e+01\n",
            " 9.963e-01 3.280e+00 6.200e-01 9.400e+00] 5 4.953700070580231 0.046299929419769015\n",
            "[ 6.2     0.58    0.      1.6     0.065   8.     18.      0.9966  3.56\n",
            "  0.84    9.4   ] 5 5.462933186602666 -0.46293318660266625\n",
            "[11.1      0.31     0.53     2.2      0.06     3.      10.       0.99572\n",
            "  3.02     0.83    10.9    ] 7 6.3989027310333775 0.6010972689666225\n",
            "[ 8.8      0.33     0.41     5.9      0.073    7.      13.       0.99658\n",
            "  3.3      0.62    12.1    ] 7 6.428712180107702 0.5712878198922979\n",
            "[ 7.7      0.43     0.25     2.6      0.073   29.      63.       0.99615\n",
            "  3.37     0.58    10.5    ] 6 5.687043427156676 0.3129565728433237\n",
            "[ 9.      0.66    0.17    3.      0.077   5.     13.      0.9976  3.29\n",
            "  0.55   10.4   ] 5 5.530156003741867 -0.5301560037418671\n",
            "[12.       0.63     0.5      1.4      0.071    6.      26.       0.99791\n",
            "  3.07     0.6     10.4    ] 4 5.634124892514275 -1.6341248925142748\n",
            "[ 6.3      0.76     0.       2.9      0.072   26.      52.       0.99379\n",
            "  3.51     0.6     11.5    ] 6 5.663831032757951 0.3361689672420489\n",
            "[ 7.      0.5     0.25    2.      0.07    3.     22.      0.9963  3.25\n",
            "  0.63    9.2   ] 5 5.353590314534967 -0.3535903145349666\n",
            "[ 8.2     0.39    0.38    1.5     0.058  10.     29.      0.9962  3.26\n",
            "  0.74    9.8   ] 5 5.751682361792057 -0.7516823617920574\n",
            "[ 8.4      0.635    0.36     2.       0.089   15.      55.       0.99745\n",
            "  3.31     0.57    10.4    ] 4 5.389051997855102 -1.389051997855102\n",
            "[ 8.3     0.54    0.28    1.9     0.077  11.     40.      0.9978  3.39\n",
            "  0.61   10.    ] 6 5.442560414234249 0.557439585765751\n",
            "[9.000e+00 6.200e-01 4.000e-02 1.900e+00 1.460e-01 2.700e+01 9.000e+01\n",
            " 9.984e-01 3.160e+00 7.000e-01 9.400e+00] 5 5.191788880653513 -0.19178888065351263\n",
            "[ 8.1     0.38    0.48    1.8     0.157   5.     17.      0.9976  3.3\n",
            "  1.05    9.4   ] 5 5.721740583231497 -0.7217405832314974\n",
            "[6.1000e+00 5.9000e-01 1.0000e-02 2.1000e+00 5.6000e-02 5.0000e+00\n",
            " 1.3000e+01 9.9472e-01 3.5200e+00 5.6000e-01 1.1400e+01] 5 5.845929637870034 -0.8459296378700341\n",
            "[ 8.2     0.73    0.21    1.7     0.074   5.     13.      0.9968  3.2\n",
            "  0.52    9.5   ] 5 5.171033531141129 -0.17103353114112885\n",
            "[ 8.      0.43    0.36    2.3     0.075  10.     48.      0.9976  3.34\n",
            "  0.46    9.4   ] 5 5.224443454147676 -0.22444345414767586\n",
            "[8.600e+00 4.900e-01 2.900e-01 2.000e+00 1.100e-01 1.900e+01 1.330e+02\n",
            " 9.972e-01 2.930e+00 1.980e+00 9.800e+00] 5 6.541189125919711 -1.5411891259197112\n",
            "[ 9.1      0.25     0.34     2.       0.071   45.      67.       0.99769\n",
            "  3.44     0.86    10.2    ] 7 6.039841595520627 0.9601584044793734\n",
            "[ 7.9      0.31     0.32     1.9      0.066   14.      36.       0.99364\n",
            "  3.41     0.56    12.6    ] 6 6.4497296841111105 -0.4497296841111105\n",
            "[10.       0.38     0.38     1.6      0.169   27.      90.       0.99914\n",
            "  3.15     0.65     8.5    ] 5 5.03145226078752 -0.03145226078752028\n",
            "[ 8.5      0.46     0.59     1.4      0.414   16.      45.       0.99702\n",
            "  3.03     1.34     9.2    ] 5 5.417623996903073 -0.41762399690307284\n",
            "[ 7.2     0.54    0.27    2.6     0.084  12.     78.      0.9964  3.39\n",
            "  0.71   11.    ] 5 5.7035089056713115 -0.7035089056713115\n",
            "[ 6.8     0.61    0.2     1.8     0.077  11.     65.      0.9971  3.54\n",
            "  0.58    9.3   ] 5 4.991365682506854 0.008634317493146249\n",
            "[10.1    0.935  0.22   3.4    0.105 11.    86.     1.001  3.43   0.64\n",
            " 11.3  ] 4 5.283215550298225 -1.283215550298225\n",
            "[ 9.9      0.72     0.55     1.7      0.136   24.      52.       0.99752\n",
            "  3.35     0.94    10.     ] 5 5.421399753353045 -0.4213997533530449\n",
            "[ 7.2     0.725   0.05    4.65    0.086   4.     11.      0.9962  3.41\n",
            "  0.39   10.9   ] 5 5.4197347513687415 -0.4197347513687415\n",
            "[5.1000e+00 4.2000e-01 0.0000e+00 1.8000e+00 4.4000e-02 1.8000e+01\n",
            " 8.8000e+01 9.9157e-01 3.6800e+00 7.3000e-01 1.3600e+01] 7 6.60247429735734 0.3975257026426604\n",
            "[7.5000e+00 6.5000e-01 1.8000e-01 7.0000e+00 8.8000e-02 2.7000e+01\n",
            " 9.4000e+01 9.9915e-01 3.3800e+00 7.7000e-01 9.4000e+00] 5 5.2023189541517425 -0.2023189541517425\n",
            "[12.4     0.49    0.58    3.      0.103  28.     99.      1.0008  3.16\n",
            "  1.     11.5   ] 6 6.2148384281116265 -0.21483842811162646\n",
            "[ 8.2      0.28     0.6      3.       0.104   10.      22.       0.99828\n",
            "  3.39     0.68    10.6    ] 5 5.895866362208571 -0.8958663622085714\n",
            "[ 5.9      0.46     0.       1.9      0.077   25.      44.       0.99385\n",
            "  3.5      0.53    11.2    ] 5 5.8328972149314104 -0.8328972149314104\n",
            "[ 8.4     0.36    0.32    2.2     0.081  32.     79.      0.9964  3.3\n",
            "  0.72   11.    ] 6 6.004144382101291 -0.0041443821012912\n",
            "[11.6         0.475       0.4         1.4         0.091       6.\n",
            " 28.          0.99704     3.07        0.65       10.03333333] 6 5.711436771314491 0.28856322868550865\n",
            "[7.7000e+00 7.1500e-01 1.0000e-02 2.1000e+00 6.4000e-02 3.1000e+01\n",
            " 4.3000e+01 9.9371e-01 3.4100e+00 5.7000e-01 1.1800e+01] 6 5.885604533558534 0.11439546644146592\n",
            "[ 8.2     0.24    0.34    5.1     0.062   8.     22.      0.9974  3.22\n",
            "  0.94   10.9   ] 6 6.476367470771851 -0.4763674707718506\n",
            "[ 6.5      0.4      0.1      2.       0.076   30.      47.       0.99554\n",
            "  3.36     0.48     9.4    ] 6 5.359934720714257 0.6400652792857429\n",
            "[ 6.8      0.68     0.09     3.9      0.068   15.      29.       0.99524\n",
            "  3.41     0.52    11.1    ] 4 5.63416904146594 -1.63416904146594\n",
            "[ 7.7     0.965   0.1     2.1     0.112  11.     22.      0.9963  3.26\n",
            "  0.5     9.5   ] 5 4.822008061986204 0.17799193801379598\n",
            "[7.5000e+00 5.8000e-01 3.0000e-02 4.1000e+00 8.0000e-02 2.7000e+01\n",
            " 4.6000e+01 9.9592e-01 3.0200e+00 4.7000e-01 9.2000e+00] 5 5.273104524970213 -0.2731045249702131\n",
            "[9.90000e+00 5.90000e-01 7.00000e-02 3.40000e+00 1.02000e-01 3.20000e+01\n",
            " 7.10000e+01 1.00015e+00 3.31000e+00 7.10000e-01 9.80000e+00] 5 5.453194020954628 -0.45319402095462813\n",
            "[ 6.9      0.52     0.25     2.6      0.081   10.      37.       0.99685\n",
            "  3.46     0.5     11.     ] 5 5.627061740838279 -0.627061740838279\n",
            "[13.      0.47    0.49    4.3     0.085   6.     47.      1.0021  3.3\n",
            "  0.68   12.7   ] 6 6.413874658446916 -0.4138746584469164\n",
            "[10.5      0.36     0.47     2.2      0.074    9.      23.       0.99638\n",
            "  3.23     0.76    12.     ] 6 6.482351587238646 -0.4823515872386457\n",
            "[ 9.       0.8      0.12     2.4      0.083    8.      28.       0.99836\n",
            "  3.33     0.65    10.4    ] 6 5.412093115607348 0.5879068843926518\n",
            "[ 7.9      0.4      0.3      1.8      0.157    2.      45.       0.99727\n",
            "  3.31     0.91     9.5    ] 6 5.550238973583124 0.4497610264168763\n",
            "[10.      0.49    0.2    11.      0.071  13.     50.      1.0015  3.16\n",
            "  0.69    9.2   ] 6 5.51288891182827 0.48711108817173\n",
            "[ 7.9      0.57     0.31     2.       0.079   10.      79.       0.99677\n",
            "  3.29     0.69     9.5    ] 6 5.24264088114349 0.7573591188565096\n",
            "[ 7.6     0.685   0.23    2.3     0.111  20.     84.      0.9964  3.21\n",
            "  0.61    9.3   ] 5 4.994008368867936 0.005991631132063802\n",
            "[10.       0.41     0.45     6.2      0.071    6.      14.       0.99702\n",
            "  3.21     0.49    11.8    ] 7 6.184397357863411 0.8156026421365894\n",
            "[ 8.1      0.87     0.       2.2      0.084   10.      31.       0.99656\n",
            "  3.25     0.5      9.8    ] 5 5.067567087940678 -0.06756708794067823\n",
            "[8.4000e+00 5.9000e-01 2.9000e-01 2.6000e+00 1.0900e-01 3.1000e+01\n",
            " 1.1900e+02 9.9801e-01 3.1500e+00 5.0000e-01 9.1000e+00] 5 4.890575440511158 0.10942455948884167\n",
            "[ 8.6      0.47     0.27     2.3      0.055   14.      28.       0.99516\n",
            "  3.18     0.8     11.2    ] 5 6.232138068285375 -1.2321380682853746\n",
            "[ 8.2      0.32     0.42     2.3      0.098    3.       9.       0.99506\n",
            "  3.27     0.55    12.3    ] 6 6.370478071157535 -0.3704780711575353\n",
            "[7.300e+00 3.650e-01 4.900e-01 2.500e+00 8.800e-02 3.900e+01 1.060e+02\n",
            " 9.966e-01 3.360e+00 7.800e-01 1.100e+01] 5 5.899748928479736 -0.8997489284797364\n",
            "[ 7.4    0.67   0.12   1.6    0.186  5.    21.     0.996  3.39   0.54\n",
            "  9.5  ] 5 4.9618406872684 0.038159312731600004\n",
            "[ 7.2      0.38     0.31     2.       0.056   15.      29.       0.99472\n",
            "  3.23     0.76    11.3    ] 8 6.266254620562965 1.7337453794370354\n",
            "[ 8.4     0.37    0.43    2.3     0.063  12.     19.      0.9955  3.17\n",
            "  0.81   11.2   ] 7 6.317405246556195 0.682594753443805\n",
            "[ 8.8     0.6     0.29    2.2     0.098   5.     15.      0.9988  3.36\n",
            "  0.49    9.1   ] 5 5.039141016263571 -0.039141016263570805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwbH5XXs_VmZ"
      },
      "source": [
        "R-squared is a goodness-of-fit measure for linear regression models. This is indicated in percentage.\n",
        "\n",
        "Root Mean Square Error (RMSE) is the standard deviation of prediction errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29epNF9Cd6nH"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZJTbk9nefvz"
      },
      "source": [
        "mulrmse= np.sqrt(mean_squared_error(y_test,pred))\n",
        "mulscore= r2_score(y_test,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xoS_2yxk0Uh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c675e8f-57b6-4eb4-f906-dd3254ea4d3f"
      },
      "source": [
        "print('r2 score ='+ str(mulscore)+' rmse='+str(mulrmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 score =0.35477507219355753 rmse=0.6522422729888263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9-vis5GMXL6"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFaKq1NsGuLG"
      },
      "source": [
        "Importing the required library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuZvjm0mMjQY"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uor5I7lFMqK_"
      },
      "source": [
        "dreg= DecisionTreeRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLx-jVXGMsO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec06553b-41e7-4a79-c28f-cf18509e42f4"
      },
      "source": [
        "dreg.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOcvGq1IMvJg"
      },
      "source": [
        "pred= dreg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAITfYfvMxca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28082b4c-90a6-4c10-e584-c1fbd0994493"
      },
      "source": [
        "for i in range(len(X_test)):\n",
        "  print(y_test[i],pred[i], pred[i]-y_test[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 5.0 -1.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "4 7.0 3.0\n",
            "7 6.0 -1.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "7 7.0 0.0\n",
            "4 5.0 1.0\n",
            "6 7.0 1.0\n",
            "5 5.0 0.0\n",
            "7 8.0 1.0\n",
            "6 6.0 0.0\n",
            "5 4.0 -1.0\n",
            "5 6.0 1.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "7 8.0 1.0\n",
            "5 5.0 0.0\n",
            "7 7.0 0.0\n",
            "4 5.0 1.0\n",
            "5 7.0 2.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "4 5.0 1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "7 7.0 0.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "7 7.0 0.0\n",
            "5 6.0 1.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 4.0 -2.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "7 7.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 7.0 1.0\n",
            "5 5.0 0.0\n",
            "4 5.0 1.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 7.0 1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "6 5.0 -1.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "7 7.0 0.0\n",
            "5 6.0 1.0\n",
            "4 6.0 2.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "7 6.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "6 4.0 -2.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "5 6.0 1.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 6.0 1.0\n",
            "7 7.0 0.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "4 4.0 0.0\n",
            "5 6.0 1.0\n",
            "5 6.0 1.0\n",
            "6 6.0 0.0\n",
            "3 6.0 3.0\n",
            "6 6.0 0.0\n",
            "7 7.0 0.0\n",
            "6 5.0 -1.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "4 5.0 1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "7 5.0 -2.0\n",
            "5 6.0 1.0\n",
            "5 6.0 1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "7 7.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "7 7.0 0.0\n",
            "6 6.0 0.0\n",
            "6 7.0 1.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 5.0 -1.0\n",
            "3 4.0 1.0\n",
            "7 7.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "7 6.0 -1.0\n",
            "6 5.0 -1.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 6.0 1.0\n",
            "6 5.0 -1.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "5 4.0 -1.0\n",
            "5 5.0 0.0\n",
            "7 5.0 -2.0\n",
            "6 5.0 -1.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "8 8.0 0.0\n",
            "7 6.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "7 5.0 -2.0\n",
            "6 7.0 1.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 8.0 2.0\n",
            "5 6.0 1.0\n",
            "6 6.0 0.0\n",
            "6 5.0 -1.0\n",
            "7 7.0 0.0\n",
            "5 5.0 0.0\n",
            "6 7.0 1.0\n",
            "5 7.0 2.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 3.0 -2.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "7 7.0 0.0\n",
            "6 5.0 -1.0\n",
            "4 6.0 2.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "7 6.0 -1.0\n",
            "7 6.0 -1.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 4.0 -2.0\n",
            "7 5.0 -2.0\n",
            "7 7.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "8 7.0 -1.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "7 7.0 0.0\n",
            "5 5.0 0.0\n",
            "7 5.0 -2.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 5.0 -1.0\n",
            "6 5.0 -1.0\n",
            "5 6.0 1.0\n",
            "6 6.0 0.0\n",
            "8 6.0 -2.0\n",
            "6 5.0 -1.0\n",
            "5 6.0 1.0\n",
            "5 4.0 -1.0\n",
            "7 5.0 -2.0\n",
            "6 7.0 1.0\n",
            "6 6.0 0.0\n",
            "5 4.0 -1.0\n",
            "5 3.0 -2.0\n",
            "7 7.0 0.0\n",
            "7 6.0 -1.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "4 5.0 1.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "4 4.0 0.0\n",
            "6 5.0 -1.0\n",
            "5 4.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 4.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "7 6.0 -1.0\n",
            "6 6.0 0.0\n",
            "5 4.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 6.0 1.0\n",
            "5 6.0 1.0\n",
            "4 5.0 1.0\n",
            "5 6.0 1.0\n",
            "5 5.0 0.0\n",
            "7 7.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 6.0 0.0\n",
            "6 5.0 -1.0\n",
            "4 7.0 3.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 6.0 0.0\n",
            "6 7.0 1.0\n",
            "6 5.0 -1.0\n",
            "6 6.0 0.0\n",
            "6 5.0 -1.0\n",
            "6 5.0 -1.0\n",
            "5 5.0 0.0\n",
            "7 6.0 -1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "6 7.0 1.0\n",
            "5 5.0 0.0\n",
            "5 5.0 0.0\n",
            "8 6.0 -2.0\n",
            "7 7.0 0.0\n",
            "5 5.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCD3bU77lAaw"
      },
      "source": [
        "dtscore= r2_score(y_test,pred)\n",
        "dtrmse= np.sqrt(mean_squared_error(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6squbVkblACa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7cb753-1192-4158-a163-086175ccac5b"
      },
      "source": [
        "print('r2 score ='+ str(dtscore)+' rmse='+str(dtrmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 score =0.07103501392262579 rmse=0.7826237921249264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOl1DKkKOYrl"
      },
      "source": [
        "##Random Forest Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv2hIp5TGHCv"
      },
      "source": [
        "Importing the library required for Random Forest Regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWYZ9zuBOfI8"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ_UYQRlOjDa"
      },
      "source": [
        "rreg= RandomForestRegressor(n_estimators=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjMPwxFQOmbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61953be5-776a-4746-a668-09ed78afb01b"
      },
      "source": [
        "rreg.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHNcPHxrlG_5"
      },
      "source": [
        "rfscore= r2_score(y_test,pred)\n",
        "rfrmse= np.sqrt(mean_squared_error(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy9ZdizklIAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4decc64-c25e-4c64-f2bc-8ac4dd187350"
      },
      "source": [
        "print('r2 score ='+ str(rfscore)+ ' rmse='+str(rfrmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 score =0.07103501392262579 rmse=0.7826237921249264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XQxInG_Ppi3"
      },
      "source": [
        "##Support Vector Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OJf8E3NGbp9"
      },
      "source": [
        "As standardising the data is required for training the data using Support Vector Regression Model, we import the required library.\n",
        "\n",
        "Standardization is the process of putting different variables on the same scale.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF2NeJyPPpGg"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAvOP1r5IrsB"
      },
      "source": [
        "Standard Scaler requires a two dimensional array.\n",
        "\n",
        "As y is a one dimensional array we reshape it to a 2D format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjTkvREYmIeR"
      },
      "source": [
        "t_train=y_train.reshape(len(y_train),1)\n",
        "t_test=y_test.reshape(len(y_test),1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqVjMnIJmI6N"
      },
      "source": [
        "X_sc=StandardScaler()\n",
        "y_sc=StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8ETeoUWmIxP"
      },
      "source": [
        "X_std_train=X_sc.fit_transform(X_train)\n",
        "y_std_train=y_sc.fit_transform(t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5w7xDhkmQnW"
      },
      "source": [
        "X_std_test=X_sc.transform(X_test)\n",
        "y_std_test=y_sc.transform(t_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT_jp72OTl5R"
      },
      "source": [
        "from sklearn.svm import SVR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY1F3kMTmZTw"
      },
      "source": [
        "sreg = SVR()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjXsRPbmmZje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0511562a-305e-445a-e325-60a84a212cd8"
      },
      "source": [
        "sreg.fit(X_std_train,y_std_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA92oP-unfDs"
      },
      "source": [
        "s_pred = sreg.predict(X_std_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7qFfhNMmZQW"
      },
      "source": [
        "sv_score= r2_score(y_std_test, s_pred)\n",
        "sv_rmse = np.sqrt(mean_squared_error(y_sc.inverse_transform(y_std_test), y_sc.inverse_transform(s_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpoaFx3JlJRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3699eb-e84f-4d66-f9a3-54bcaaba9372"
      },
      "source": [
        "print('r2 score support vector ='+ str(sv_score)+' rmse support vector='+str(sv_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 score support vector =0.3857276589907429 rmse support vector=0.6364053973998478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvZVnpI8URZ8"
      },
      "source": [
        "##R2 score and RMSE Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DALS5UpGUXLy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3c0b794d-1e92-4c92-fae9-e1169618c9f8"
      },
      "source": [
        "print('r2 score multiplelinear ='+ str(mulscore)+' rmse multiplelinear ='+str(mulrmse))\n",
        "print('r2 score decision tree  ='+ str(dtscore)+' rmse decision tree   ='+str(dtrmse))\n",
        "print('r2 score random forest  ='+ str(rfscore)+ ' rmse random forest  ='+str(rfrmse))\n",
        "print('r2 score support vector ='+ str(sv_score)+' rmse support vector ='+str(sv_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r2 score multiplelinear =0.35477507219355753 rmse multiplelinear =0.6522422729888263\n",
            "r2 score decision tree  =0.07103501392262579 rmse decision tree   =0.7826237921249264\n",
            "r2 score random forest  =0.07103501392262579 rmse random forest  =0.7826237921249264\n",
            "r2 score support vector =0.3857276589907429 rmse support vector =0.6364053973998478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h95bBhLsJNDW"
      },
      "source": [
        "As Support Vector Regression shows highest percentage of R-Squared value and least RMSE error it is the best fit Model to predict the Quality of the Red Wine in this dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_gwpk1YxCH_"
      },
      "source": [
        "#CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-p6E8YACxEa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2kk-R9zC8f1"
      },
      "source": [
        "dataset= pd.read_csv('/content/winequality-red.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkUCUOEaEWGo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "c83b7ca0-a8f3-4bde-bdd4-a45059156e5f"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0               7.4             0.700         0.00  ...       0.56      9.4        5\n",
              "1               7.8             0.880         0.00  ...       0.68      9.8        5\n",
              "2               7.8             0.760         0.04  ...       0.65      9.8        5\n",
              "3              11.2             0.280         0.56  ...       0.58      9.8        6\n",
              "4               7.4             0.700         0.00  ...       0.56      9.4        5\n",
              "...             ...               ...          ...  ...        ...      ...      ...\n",
              "1594            6.2             0.600         0.08  ...       0.58     10.5        5\n",
              "1595            5.9             0.550         0.10  ...       0.76     11.2        6\n",
              "1596            6.3             0.510         0.13  ...       0.75     11.0        6\n",
              "1597            5.9             0.645         0.12  ...       0.71     10.2        5\n",
              "1598            6.0             0.310         0.47  ...       0.66     11.0        6\n",
              "\n",
              "[1599 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zpvSFWAEdkU"
      },
      "source": [
        "X = dataset.iloc[:,:-1].values\n",
        "y= dataset.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBa1d9FDE5ZL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2f46c55c-1c86-49a2-d5f3-ec37a4b795cb"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.4  ,  0.7  ,  0.   , ...,  3.51 ,  0.56 ,  9.4  ],\n",
              "       [ 7.8  ,  0.88 ,  0.   , ...,  3.2  ,  0.68 ,  9.8  ],\n",
              "       [ 7.8  ,  0.76 ,  0.04 , ...,  3.26 ,  0.65 ,  9.8  ],\n",
              "       ...,\n",
              "       [ 6.3  ,  0.51 ,  0.13 , ...,  3.42 ,  0.75 , 11.   ],\n",
              "       [ 5.9  ,  0.645,  0.12 , ...,  3.57 ,  0.71 , 10.2  ],\n",
              "       [ 6.   ,  0.31 ,  0.47 , ...,  3.39 ,  0.66 , 11.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xeHA8DCE9KW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3008869d-727a-44ee-e8fc-30ee2998acb8"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, ..., 6, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQYWyPv_FAcs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4D5APPcFVDh"
      },
      "source": [
        "X_train,X_test, y_train , y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfH9TX_HGDB4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c154e28-d279-4ef5-9ad0-8df4c1538123"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1279"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-9CQtWeeBcV"
      },
      "source": [
        "Importing the Standard scaler and creating the object of it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JodlmLEyGGBH"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQdC9HmDGahL"
      },
      "source": [
        "sc = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzzfg9ZtGh0r"
      },
      "source": [
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuBfjcKfHF55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "02f303fe-bf19-4389-f7f6-dbdaa1eaa978"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.21116898, -1.47378959,  1.08440497, ...,  0.12616033,\n",
              "         1.2102129 ,  0.42678564],\n",
              "       [-0.529963  ,  0.4101622 , -0.05926021, ..., -0.13119065,\n",
              "        -0.5730386 , -0.59594425],\n",
              "       [-0.41388754, -0.36558265, -0.83903193, ..., -0.64589261,\n",
              "        -0.51551435, -0.40999336],\n",
              "       ...,\n",
              "       [ 0.86294258,  0.74262429,  0.61654194, ...,  0.38351132,\n",
              "         0.28982503,  0.98463832],\n",
              "       [ 1.50135764,  0.02228978,  1.13638975, ..., -1.54662105,\n",
              "        -0.5730386 ,  1.17058921],\n",
              "       [-1.11034033,  0.63180359, -0.31918412, ...,  1.79894172,\n",
              "         0.00220382, -0.59594425]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZxNvC7evH5_"
      },
      "source": [
        "##Logic Regression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbLeOsCVfbtl"
      },
      "source": [
        "importing the required library and creating an object lcla of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D4Unl_0HRWQ"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSaKKs0FHq-2"
      },
      "source": [
        "lcla= LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig6cYougfmzs"
      },
      "source": [
        "the dataset is trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX8FT263Hurr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851bf0a7-5b69-46b8-be39-5e4854362767"
      },
      "source": [
        "lcla.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZSbkqi0I1Ks"
      },
      "source": [
        "pred=lcla.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foHO_etlI6ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ae8598-3d7b-449f-82eb-022211612c10"
      },
      "source": [
        "for i in range(len(pred)):\n",
        "  print(pred[i] , y_test[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 6\n",
            "5 6\n",
            "5 5\n",
            "6 6\n",
            "5 6\n",
            "5 5\n",
            "5 5\n",
            "5 3\n",
            "5 4\n",
            "5 6\n",
            "6 5\n",
            "5 5\n",
            "6 6\n",
            "6 6\n",
            "6 6\n",
            "5 5\n",
            "6 5\n",
            "6 6\n",
            "7 8\n",
            "5 4\n",
            "5 5\n",
            "7 7\n",
            "5 5\n",
            "5 5\n",
            "5 6\n",
            "5 5\n",
            "6 6\n",
            "6 5\n",
            "6 6\n",
            "5 6\n",
            "5 5\n",
            "5 6\n",
            "5 6\n",
            "5 5\n",
            "6 5\n",
            "5 5\n",
            "6 5\n",
            "5 5\n",
            "5 5\n",
            "5 6\n",
            "5 5\n",
            "7 7\n",
            "6 6\n",
            "6 5\n",
            "6 5\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "6 6\n",
            "5 5\n",
            "5 5\n",
            "7 7\n",
            "5 5\n",
            "5 6\n",
            "5 5\n",
            "6 7\n",
            "5 5\n",
            "5 6\n",
            "5 6\n",
            "6 6\n",
            "5 5\n",
            "5 6\n",
            "5 5\n",
            "5 5\n",
            "6 5\n",
            "6 6\n",
            "5 6\n",
            "6 5\n",
            "5 5\n",
            "6 6\n",
            "6 7\n",
            "5 5\n",
            "6 6\n",
            "6 6\n",
            "6 6\n",
            "5 4\n",
            "7 6\n",
            "6 4\n",
            "7 6\n",
            "6 5\n",
            "5 5\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "6 6\n",
            "6 6\n",
            "6 6\n",
            "6 6\n",
            "7 7\n",
            "6 5\n",
            "6 7\n",
            "6 5\n",
            "7 7\n",
            "7 6\n",
            "5 6\n",
            "5 5\n",
            "7 6\n",
            "5 5\n",
            "5 6\n",
            "6 8\n",
            "5 6\n",
            "6 6\n",
            "5 6\n",
            "6 5\n",
            "7 7\n",
            "5 6\n",
            "5 5\n",
            "5 6\n",
            "5 6\n",
            "5 5\n",
            "5 6\n",
            "6 6\n",
            "6 6\n",
            "5 5\n",
            "6 7\n",
            "7 7\n",
            "7 6\n",
            "5 5\n",
            "6 5\n",
            "5 5\n",
            "6 6\n",
            "5 5\n",
            "5 6\n",
            "7 6\n",
            "5 5\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "6 7\n",
            "6 6\n",
            "7 8\n",
            "5 6\n",
            "7 6\n",
            "5 6\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "5 5\n",
            "6 6\n",
            "5 5\n",
            "6 7\n",
            "6 6\n",
            "6 6\n",
            "6 6\n",
            "5 6\n",
            "5 5\n",
            "6 5\n",
            "6 6\n",
            "6 7\n",
            "5 5\n",
            "6 5\n",
            "6 6\n",
            "7 6\n",
            "6 5\n",
            "5 6\n",
            "6 6\n",
            "6 5\n",
            "6 5\n",
            "6 6\n",
            "6 6\n",
            "5 5\n",
            "6 5\n",
            "5 6\n",
            "7 7\n",
            "6 6\n",
            "5 5\n",
            "6 6\n",
            "5 5\n",
            "6 7\n",
            "6 6\n",
            "6 6\n",
            "6 6\n",
            "6 5\n",
            "5 6\n",
            "6 5\n",
            "5 6\n",
            "6 5\n",
            "6 5\n",
            "6 6\n",
            "5 6\n",
            "5 6\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "5 5\n",
            "6 6\n",
            "5 6\n",
            "5 4\n",
            "6 5\n",
            "5 5\n",
            "6 6\n",
            "6 6\n",
            "6 6\n",
            "5 5\n",
            "6 4\n",
            "5 5\n",
            "5 5\n",
            "6 5\n",
            "6 6\n",
            "5 4\n",
            "5 6\n",
            "5 6\n",
            "7 6\n",
            "5 5\n",
            "5 5\n",
            "5 5\n",
            "5 6\n",
            "6 6\n",
            "5 4\n",
            "5 5\n",
            "5 5\n",
            "5 5\n",
            "6 5\n",
            "5 6\n",
            "5 5\n",
            "5 6\n",
            "5 5\n",
            "6 6\n",
            "6 6\n",
            "5 5\n",
            "5 5\n",
            "5 7\n",
            "6 6\n",
            "6 5\n",
            "5 6\n",
            "5 5\n",
            "6 6\n",
            "5 5\n",
            "6 6\n",
            "6 7\n",
            "6 6\n",
            "5 5\n",
            "7 6\n",
            "5 5\n",
            "6 7\n",
            "5 5\n",
            "7 6\n",
            "6 5\n",
            "5 5\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "5 6\n",
            "5 5\n",
            "7 7\n",
            "5 5\n",
            "5 5\n",
            "5 5\n",
            "5 5\n",
            "7 6\n",
            "6 6\n",
            "5 5\n",
            "6 5\n",
            "5 7\n",
            "6 6\n",
            "5 6\n",
            "5 3\n",
            "5 5\n",
            "5 6\n",
            "7 6\n",
            "5 5\n",
            "7 7\n",
            "5 5\n",
            "5 6\n",
            "6 6\n",
            "6 7\n",
            "6 5\n",
            "5 6\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "5 6\n",
            "6 5\n",
            "5 6\n",
            "5 5\n",
            "5 6\n",
            "6 6\n",
            "5 5\n",
            "5 6\n",
            "6 5\n",
            "6 6\n",
            "5 5\n",
            "6 5\n",
            "6 6\n",
            "5 5\n",
            "5 5\n",
            "5 6\n",
            "7 4\n",
            "5 5\n",
            "5 4\n",
            "6 6\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "5 5\n",
            "5 6\n",
            "6 7\n",
            "6 7\n",
            "6 7\n",
            "5 5\n",
            "5 5\n",
            "5 5\n",
            "6 6\n",
            "6 6\n",
            "6 5\n",
            "6 5\n",
            "6 5\n",
            "5 6\n",
            "5 6\n",
            "5 5\n",
            "5 6\n",
            "5 5\n",
            "6 6\n",
            "5 5\n",
            "6 7\n",
            "6 6\n",
            "5 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAG81L08fZrz"
      },
      "source": [
        "Accuracy Score is the ratio of number of correct predictions to the total number of input samples. \n",
        "\n",
        "The Confusion matrix compares the actual target values with those predicted by the machine learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAiuq1kDgopW"
      },
      "source": [
        "importing accuracy score and confusion matrix and creating objects of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvwa3Jj4JQs7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score , confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAmNwifnL0Im"
      },
      "source": [
        "ac_l = accuracy_score(y_test, pred)\n",
        "cm_l = confusion_matrix(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHSBvwwyMBZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ea90b1-44a6-4f5a-b50a-ec26a675c467"
      },
      "source": [
        "ac_l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.578125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nZgfDBPMDOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b0bb455-3ccb-4f4d-dcb8-4d1036dae879"
      },
      "source": [
        "cm_l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   2,   0,   0,   0],\n",
              "       [  0,   0,   7,   2,   1,   0],\n",
              "       [  0,   0, 104,  37,   0,   0],\n",
              "       [  0,   0,  52,  71,  14,   0],\n",
              "       [  0,   0,   2,  15,  10,   0],\n",
              "       [  0,   0,   0,   1,   2,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUBDo85JRUwG"
      },
      "source": [
        "##Decision Tree "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa7GPSHXSlPq"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNPhgkEoSzEE"
      },
      "source": [
        "dcla =  DecisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6vnGqyES6rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135b224e-d3fd-4524-e1b7-995c89956275"
      },
      "source": [
        "dcla.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXbJ3MlBTfgt"
      },
      "source": [
        " Predicting the test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHkK2LyVTlT_"
      },
      "source": [
        "pred = dcla.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YiHJ_aWTvU2"
      },
      "source": [
        "Making the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEBkS4sxTtqu"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyzXKAJFT6Sr"
      },
      "source": [
        "cm_d = confusion_matrix(y_test, pred)\n",
        "ac_d = accuracy_score(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdI7bkoWULGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc64e716-7279-44da-dcd3-3b9bb4ec4cd0"
      },
      "source": [
        "cm_d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  0,  1,  0,  0,  0],\n",
              "       [ 0,  0,  4,  4,  2,  0],\n",
              "       [ 2,  2, 95, 36,  6,  0],\n",
              "       [ 0,  1, 37, 76, 22,  1],\n",
              "       [ 0,  0,  2,  7, 17,  1],\n",
              "       [ 0,  0,  0,  1,  2,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG8nNPG5UMe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8baac4e-ecbb-4f7a-90af-7804e2eeeaba"
      },
      "source": [
        "ac_d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.590625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsLPyxuXWa7g"
      },
      "source": [
        "##Random Forest Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uberQqfWhvX"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmlTQp_uW1zr"
      },
      "source": [
        "rcla = RandomForestClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFEfH4x9W88_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd8e39f-6fe8-4437-fb0e-4bef863fff0a"
      },
      "source": [
        "rcla.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrl0dNfpXXxL"
      },
      "source": [
        "pred = rcla.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R1GJZpHXeWq"
      },
      "source": [
        "from sklearn.metrics import accuracy_score , confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WTmVaifXlLH"
      },
      "source": [
        "ac_r =  accuracy_score(y_test , pred)\n",
        "cm_r = confusion_matrix(y_test , pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VE9cxUQX0ra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af34c46b-7fa6-42a2-c6d5-c08218c88070"
      },
      "source": [
        "ac_r"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.68125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lxvn-fVX2DS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40213cf8-df22-45da-8787-6102d65a67d3"
      },
      "source": [
        "cm_r"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   1,   1,   0,   0],\n",
              "       [  0,   0,   5,   5,   0,   0],\n",
              "       [  0,   0, 116,  25,   0,   0],\n",
              "       [  0,   0,  35,  86,  16,   0],\n",
              "       [  0,   0,   1,  10,  16,   0],\n",
              "       [  0,   0,   0,   1,   2,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpOH-7E8YR3c"
      },
      "source": [
        "## K Nearest Neighbors Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_728OH9sPrl"
      },
      "source": [
        "Preprocess the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9rzZ4PMYbLx"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edRZKAIYs1CW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f66a9f-c4ca-4f4f-8c8d-18f7b11cb955"
      },
      "source": [
        "kcla = KNeighborsClassifier()\n",
        "kcla.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sCiYO4StAGA"
      },
      "source": [
        "pred = kcla.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oo3ihK1tDwN"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgk-8ZWdtK7h"
      },
      "source": [
        "cm_k = confusion_matrix(y_test, pred)\n",
        "ac_k = accuracy_score(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxkMeifjtQY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec4237b8-581f-40b3-ffce-5e338804875a"
      },
      "source": [
        "cm_k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  1,  1,  0,  0],\n",
              "       [ 0,  1,  4,  5,  0,  0],\n",
              "       [ 0,  4, 96, 39,  2,  0],\n",
              "       [ 0,  1, 51, 74, 10,  1],\n",
              "       [ 0,  1,  6,  9, 11,  0],\n",
              "       [ 0,  0,  0,  1,  2,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av2L4pzVtRoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a9d35e-7a29-442b-fa0b-024457fdc7da"
      },
      "source": [
        "ac_k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.56875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_g7Pr_fv7zE"
      },
      "source": [
        "##Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IFPFKIav7PV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e9f35431-e234-4822-a960-13cf08114737"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "scla = SVC(kernel='linear')\n",
        "scla.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jto7QQKh0NbO"
      },
      "source": [
        "y_pred = scla.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDkID57O0fqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "89e12b61-0dc7-4139-8688-5e6e0f655ba7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "cm_s = confusion_matrix(y_test, y_pred)\n",
        "ac_s = accuracy_score(y_test,y_pred)\n",
        "print(cm_s)\n",
        "print(ac_s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   2   0   0   0]\n",
            " [  0   0   8   2   0   0]\n",
            " [  0   0 108  33   0   0]\n",
            " [  0   0  57  66  14   0]\n",
            " [  0   0   3  18   6   0]\n",
            " [  0   0   0   1   2   0]]\n",
            "0.5625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4U4n66LMrYf"
      },
      "source": [
        "## Accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IitviwREki6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce7083d3-c919-4565-fe19-d9db63c34da4"
      },
      "source": [
        "print(ac_l, ac_d , ac_r , ac_k , ac_s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.578125 0.590625 0.68125 0.56875 0.5625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efoO1GFHlAh-"
      },
      "source": [
        "As Random Forest Classification gives the highest accuracy score of 68.1% it is the best fit model."
      ]
    }
  ]
}